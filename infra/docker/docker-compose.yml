# infra/docker/docker-compose.yml
# Docker Compose setup for local development environment

version: '3.8'

services:
  db: # Renamed from postgres
    image: postgres:15 # Changed image to standard postgres:15
    container_name: db # Renamed container
    environment:
      POSTGRES_DB: reality_engine # Updated DB name
      POSTGRES_USER: app_user # Updated user
      POSTGRES_PASSWORD: change_me # Updated password - Use secrets in production!
    volumes:
      - db_data:/var/lib/postgresql/data # Renamed volume reference
      # Optional: Mount init scripts if needed
      # - ../sql:/docker-entrypoint-initdb.d
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U app_user -d reality_engine"] # Updated healthcheck
      interval: 10s
      timeout: 5s
      retries: 5
    restart: unless-stopped

  redis:
    image: redis:7-alpine
    container_name: redis_cache
    volumes:
      - redis_data:/data
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
    restart: unless-stopped

  zookeeper:
    image: confluentinc/cp-zookeeper:7.5.0
    container_name: zookeeper
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    restart: unless-stopped

  kafka:
    image: confluentinc/cp-kafka:7.5.0
    container_name: kafka
    depends_on: # Removed schema-registry dependency from kafka
      zookeeper:
        condition: service_started
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_INTERNAL:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://localhost:9092,PLAINTEXT_INTERNAL://kafka:9093
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1 # Development setting
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1 # Development setting
    restart: unless-stopped

  schema-registry:
    image: confluentinc/cp-schema-registry:7.5.0
    container_name: schema-registry
    depends_on:
      kafka:
        condition: service_started
    environment:
      SCHEMA_REGISTRY_HOST_NAME: schema-registry
      SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: kafka:9093 # Use internal listener, without scheme
      SCHEMA_REGISTRY_KAFKASTORE_SECURITY_PROTOCOL: PLAINTEXT # Explicitly set protocol
      SCHEMA_REGISTRY_LISTENERS: http://0.0.0.0:8081
    # Removed healthcheck due to persistent failures
    # healthcheck:
    #   test: ["CMD-SHELL", "curl -f http://schema-registry:8081 || exit 1"]
    #   interval: 10s
    #   timeout: 5s
    #   retries: 5
    #   start_period: 30s
    restart: unless-stopped

  app: # Added app service definition correctly under 'services'
    build:
      context: ../.. # Build context is the project root relative to this file
      dockerfile: Dockerfile # Dockerfile in the project root
    container_name: reality_engine_app
    volumes:
      - ../..:/app # Mount project root to /app in container
    depends_on:
      db:
        condition: service_healthy
      redis:
        condition: service_healthy
      kafka:
        condition: service_started # Kafka doesn't have a healthcheck here
      schema-registry:
        condition: service_started # Reverted to service_started as healthcheck was removed
    environment:
      # Database connection (adjust if needed based on actual usage)
      DATABASE_URL: postgresql://app_user:change_me@db:5432/reality_engine
      # Redis connection
      REDIS_URL: redis://redis_cache:6379/0
      # Kafka connection details (using internal listener for tests within docker)
      KAFKA_BOOTSTRAP: kafka:9093
      SCHEMA_REGISTRY_URL: http://schema-registry:8081
      # Ensure Python path includes src
      PYTHONPATH: /app
    # Override default command for testing or development
    # Use sleep infinity for a more robust way to keep container running
    command: sleep infinity
    # No restart needed for test runs usually
    # restart: unless-stopped

  neo4j:
    image: neo4j:5 # Use a specific version, e.g., 5
    container_name: neo4j_graph
    environment:
      # Set a password for the neo4j user. Use secrets in production!
      NEO4J_AUTH: neo4j/change_this_password
      # Optional: Configure memory limits if needed
      # NEO4J_server_memory_pagecache_size: 1G
      # NEO4J_server_memory_heap_initial__size: 1G
      # NEO4J_server_memory_heap_max__size: 1G
    ports:
      - "7474:7474" # Neo4j Browser UI (HTTP)
      - "7687:7687" # Bolt protocol
    volumes:
      - neo4j_data:/data
    healthcheck:
      # Check if the Bolt port is open and responding
      # Use curl against the HTTP endpoint, which is often available earlier and curl is common
      # Use cypher-shell to check Bolt connectivity and basic query execution
      test: ["CMD-SHELL", "cypher-shell -u neo4j -p change_this_password -a bolt://localhost:7687 'RETURN 1' || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 20s # Give Neo4j time to start
    restart: unless-stopped

  kg_service:
    build:
      context: ../.. # Project root relative to this docker-compose file
      dockerfile: services/kg/Dockerfile # Path to the KG service Dockerfile
    container_name: kg_service
    depends_on:
      kafka:
        condition: service_started # Wait for Kafka to be available
      neo4j:
        condition: service_healthy # Wait for Neo4j to be healthy
    environment:
      # Kafka connection details (use internal listener)
      KAFKA_BOOTSTRAP_SERVERS: kafka:9093
      SCHEMA_REGISTRY_URL: http://schema-registry:8081
      # Neo4j connection details (match the neo4j service)
      NEO4J_URI: bolt://neo4j:7687
      NEO4J_USER: neo4j
      NEO4J_PASSWORD: change_this_password # MUST MATCH NEO4J_AUTH password
      NEO4J_DATABASE: neo4j # Default database
      # Logging level for the service
      LOG_LEVEL: INFO
      # Ensure Python path includes base app dir for shared modules
      PYTHONPATH: /app
    # Optional: Mount code for development (if not relying solely on build)
    # volumes:
    #   - ../..:/app
    healthcheck:
      # Basic healthcheck: Check if the main Python process is running
      # A more robust check would involve a script verifying Kafka/Neo4j connectivity
      # or a dedicated health endpoint if the service had one.
      test: ["CMD-SHELL", "pgrep -f '/app/services/kg/main.py' || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 15s # Give consumers time to start
    restart: unless-stopped

# Top-level volumes definition (no indentation)
volumes:
  db_data: # Renamed volume definition
    driver: local
  redis_data:
    driver: local
  neo4j_data:
    driver: local
  # app_code: # Removed named volume, direct mount is better for dev/test